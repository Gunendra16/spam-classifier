{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e4da7-96cc-4ec6-a77d-8f2201640ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28c64d-12f2-4515-a1f0-c7911ea74e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f68d65-1b46-4680-b6d9-070db02e6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### agr hum direct file ko df variable me store krane chalenhe\n",
    "#### to decode nhi kr payega error aega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f9f952-2b29-4aa6-9f6c-dfdf425d5d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to  read with encoding: utf-8\n",
      "File successfully read with encoding: latin1\n",
      "CSV file has been successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### list all the possible encodings to try\n",
    "encodings = ['utf-8' , 'latin1','ISO-8859-1', 'cp1252']\n",
    "\n",
    "file_path = 'spam.csv'\n",
    "\n",
    "#### attempt to read the csv file with different encdings\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "        print(f\"File successfully read with encoding: {encoding}\")\n",
    "        break ## try the next encoding\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"failed to  read with encoding: {encoding}\")\n",
    "\n",
    "#### if the loop completes without success, df will not be defined \n",
    "if 'df' in locals():\n",
    "    print(\"CSV file has been successfully loaded.\")\n",
    "else:\n",
    "    print(\"ll encoding attempts failed, unable to read the csv file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b172f0-6b5b-4983-a843-abd7ae08e3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ham</td>\n",
       "      <td>I cant pick the phone right now. Pls send a me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Û_ and donÛ÷t worry weÛ÷ll have finished by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>ham</td>\n",
       "      <td>G.W.R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did u got that persons story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>ham</td>\n",
       "      <td>No drama Pls.i have had enough from you and fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2 Unnamed: 2  \\\n",
       "298   ham  I cant pick the phone right now. Pls send a me...        NaN   \n",
       "2571  ham  Û_ and donÛ÷t worry weÛ÷ll have finished by...        NaN   \n",
       "4291  ham                                              G.W.R        NaN   \n",
       "654   ham                       Did u got that persons story        NaN   \n",
       "2492  ham  No drama Pls.i have had enough from you and fa...        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "298         NaN        NaN  \n",
       "2571        NaN        NaN  \n",
       "4291        NaN        NaN  \n",
       "654         NaN        NaN  \n",
       "2492        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff21781-56e3-4e6d-83c7-919076ae3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b0eba-5821-4921-a8cb-2927900fce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### yaha hume spam aur ham dikh rha hai matab spam hai spam mail aur ham hai legid mail\n",
    "#### aur hume ye NaN wali entries bhrni jb hum age processing krenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4931d86-4380-4c29-b480-4b9b8a25df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf3a55-5e53-4415-956b-284ead0ec130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### means 5572 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daa39f-5f2f-46e0-9961-e679b22f1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project consists of\n",
    "## 1. data cleaning\n",
    "## 2. EDA\n",
    "## 3. Model building\n",
    "## 4. Evaluation\n",
    "## 5. Improvement\n",
    "## 6. deploy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecc228-910b-4503-aef3-51a263272ff6",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc17891-3c93-4d65-a34e-78b49af592d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fa9a9-8a5e-4715-88bd-2fc16dcb5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### drop last 3 cols\n",
    "df.drop( columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52370b0-1f0a-4cac-b34f-2c465b44835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e24021-8238-4fe7-b904-7e94297e59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### renaming the cols\n",
    "df.rename(columns = { 'v1':'target' , 'v2':'text'} , inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ea933-0334-44ad-a764-acbc67e9b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415b227-04f6-423c-9432-2dc43fa38ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### labelEncoder is commonly used to convert categorical labels into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19404f4-8bbc-43d5-bba6-469558b17b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']= encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b0ec5-989a-4482-96fc-d684209d5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f381b-1bd4-44a8-a142-2d8caac3bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a6360-92b9-4ccc-99d4-da93ed17104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### df.isnull().sum() is used to count the number of missing values (NaNs) in each column of a pandas DataFrame df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e51b5-a2f8-4beb-8102-e666a3384137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check for duplicates values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1ebf-7878-402e-aa30-d20bda46a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### remove duplicates\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485432f-15eb-498e-ac1b-d01267d7e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c070d-a1ac-414a-95cc-6187d45d6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17aac1d-efa0-4d0c-baf5-1fe951507791",
   "metadata": {},
   "source": [
    "# 2. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf685115-05c1-465a-a32c-b3bfab82881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd69785-d4df-4a98-83e5-bff3f5ede36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47307e-14f6-4016-9eda-54554e639fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['target'].value_counts(), labels = ['ham','spam'], autopct=\"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3558924-ed03-4f6a-a318-7da72a6e3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df['target'] contains 'ham' and 'spam' values\n",
    "value_counts = df['target'].value_counts()\n",
    "\n",
    "plt.bar(value_counts.index, value_counts.values)\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Target Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b586943-c377-448c-ae86-b0a725b33230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### big chunk of ham and very less space so out dta is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602437f-5757-4611-86a8-2fd185b5cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa6ab0-7954-48e0-a984-a12fe317d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e76676-c369-4a9c-9aea-1b9858448933",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0c316-2e34-4441-b45e-0e40653269ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nums_characters']= df['text'].apply(len) #number of character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520eb84-41b3-4c73-a9fc-45864e9ac98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e375db5-b7f1-45b2-9a2c-3de26e4d1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### number of words\n",
    "df['num_words'] = df['text'].apply(lambda x: len(nltk.word_tokenize(x)))  #word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb18f8-dbd8-4250-9ff0-bf07488f621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e715a2-6737-4b2d-94cc-d5a6209266bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nums_sentences'] = df['text'].apply(lambda x: len(nltk.sent_tokenize(x))) #sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59baac-e09a-4846-bde3-6e3337c165f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e0b33-0518-4a78-9b95-c40af7ba8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['nums_characters', 'num_words','nums_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fec3d0-d29b-42ab-847b-c1ff4f0415c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targeting ham\n",
    "df[df['target'] == 0][['nums_characters', 'num_words', 'nums_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0dbdb-f50b-415d-a5d3-5fa4c01f709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['target'] == 1][['nums_characters', 'num_words', 'nums_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267e4aa-3f9c-4899-9881-d7402fca88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce75eb-2b1c-4907-bd1b-999076d4998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df[df['target']==0]['nums_characters'])\n",
    "sns.histplot(df[df['target']==1]['nums_characters'], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227662c8-416b-4b3e-b19f-8c5ff72b45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df[df['target']==0]['num_words'])\n",
    "sns.histplot(df[df['target']==1]['num_words'], color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff07665-deda-4b5c-923d-429a8bf78cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the option to handle inf values as NA\n",
    "pd.set_option('mode.use_inf_as_na', True)\n",
    "\n",
    "# Call sns.pairplot\n",
    "sns.pairplot(df, hue='target')\n",
    "\n",
    "# Reset the option to default\n",
    "pd.set_option('mode.use_inf_as_na', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1521d-1e35-4b5b-8826-2524b7f80c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns\n",
    "#numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(numeric_df.corr(), annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7141487-3b09-4d9d-a707-b375f10dae27",
   "metadata": {},
   "source": [
    "# 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bdf2ff-abce-40b7-8a50-06885ef13cdd",
   "metadata": {},
   "source": [
    "#### lower case\n",
    "#### tokenization\n",
    "#### removing special characters\n",
    "#### removing stop words and punctation\n",
    "#### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3741ea-95fc-4562-8d6b-ddfd611b5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(y)\n",
    "\n",
    "transformed_text = transform_text(\"I'm gonna be home soon and I don't want to talk about this stuff anymore tonight, k? I've cried enough today\")\n",
    "print(transformed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27f4d7-cd6f-4ddc-859c-e785c46dda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a88e00-37a9-41f5-a55c-c8ad5441b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('walking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472b574-77b6-4398-bcbb-0c2e6f041c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82577c2-8846-4931-bf84-12c8fa43694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0b7b9-c5ae-4cdb-a189-0e5f8a660af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc= WordCloud(width=500, height=500, min_font_size=10,background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02b465-c347-4868-bcaf-8fad10a839a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_wc=wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42ed88-abf4-4630-95a4-f166737a06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3eaf7e-31af-4c49-ae2b-75f71cc237ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wc=wc.generate(df[df['target'] == 0]['transformed_text'].str.cat(sep=\" \"))\n",
    "plt.imshow(ham_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d01af-4003-4b9c-8429-bd20841c8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9e9d29-15af-4706-86de-a89cc83a00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus = []\n",
    "for msg in df[df['target']==1]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48a60c-f25c-4982-8368-f29b5a56e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus) #### this will give us the total number characters used in spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc5002-b4a1-4ffe-bcc6-733f271ce60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sns.barplot(data=pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['Word', 'Frequency']), x='Word', y='Frequency')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2a705-a476-472e-b689-63be38271f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_corpus = []\n",
    "for msg in df[df['target']==0]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31e82b-dc3b-4f7b-86ae-823c647bd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_corpus) #### characters in ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70d3d7-4a4c-4e83-8f42-5baeabe50eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sns.barplot(data=pd.DataFrame(Counter(ham_corpus).most_common(30), columns=['Word', 'Frequency']), x='Word', y='Frequency')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54171a82-560f-4590-bcdc-c3bfa71cc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fb1d6-2012-4b49-be18-bb15d13b1c67",
   "metadata": {},
   "source": [
    "# 4. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e7d5e-9245-4c2a-9c16-bc6de0305400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1910878-971d-453a-aed3-8cd7988cd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['transformed_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916741b-826a-4ce6-a227-28819bd54b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c8749-531f-47f3-b78f-22e86a6e0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba4eb0-5e3b-4c55-9c30-a9e5e9294185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee85741-4f2c-4b32-97cb-2a48637243d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train , y_test = train_test_split(X , y ,test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9a085-9a42-4dc8-a1c8-166db067e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB , MultinomialNB , BernoulliNB\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix , precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ccf6e-c48e-41cb-aecf-1050fa39e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef476a1-a28d-478d-9bb0-7ebf04b99f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train , y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test , y_pred1))\n",
    "print(confusion_matrix(y_test , y_pred1))\n",
    "print(precision_score(y_test , y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c86265-028b-4745-979e-a0719f83c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train , y_train)\n",
    "y_pred1 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test , y_pred1))\n",
    "print(confusion_matrix(y_test , y_pred1))\n",
    "print(precision_score(y_test , y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61eb95-73fa-4f92-8b22-e3f1e2524d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train , y_train)\n",
    "y_pred1 = bnb.predict(X_test)\n",
    "print(accuracy_score(y_test , y_pred1))\n",
    "print(confusion_matrix(y_test , y_pred1))\n",
    "print(precision_score(y_test , y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83704a8-a8d0-4d00-aedd-f84a04b8609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### tfidf--> MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dac27-5970-4e88-b4e0-baeddf4f393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78e12a-b32f-4eaf-ab40-6d557e98e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad40bbb-81da-4fc3-9ef8-83b7013c2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC( kernel= 'sigmoid' , gamma = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier()\n",
    "lrc = LogisticRegression(solver= 'liblinear' , penalty = 'l1')\n",
    "rfc = RandomForestClassifier( n_estimators=50,random_state=2 )\n",
    "abc = AdaBoostClassifier(n_estimators=50,random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50,random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50,random_state=2)\n",
    "gdbt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
    "xgb= XGBClassifier(n_estimators=50,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a1b65-03bc-4108-8ecf-debc97592263",
   "metadata": {},
   "outputs": [],
   "source": [
    " clfs = {\n",
    "         'SVC' : svc,\n",
    "     'KN' : knc,\n",
    "     'NB' : mnb,\n",
    "     'DT' : dtc,\n",
    "     'LR' : lrc,\n",
    "     'RF' : rfc,\n",
    "     'AdaBoost' : abc,\n",
    "     'BgC' : bc,\n",
    "     'ETC' : etc,\n",
    "     'GBDT' : gdbt,\n",
    "     'xgb' : xgb\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ddf5e-b371-4acb-a2e0-69382d7b9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf , X_train ,y_train, X_test , y_test):\n",
    "    clf.fit( X_train, y_train )\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "\n",
    "    return accuracy,precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcda3c5-52b5-4acf-b2ca-43626ad53b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(svc,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fccb9b-385f-404a-8483-b097e62de212",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores=[]\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "\n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train, X_test , y_test)\n",
    "\n",
    "    print(\"For\",name)\n",
    "    print(\"Accuracy - \", current_accuracy)\n",
    "    print(\"Precision - \", current_precision)\n",
    "\n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687e276-bdf1-4500-bce2-030a1c78d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame({'Algorithm' :clfs.keys(), 'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9d552-ea40-4760-af29-7348cc962dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac7b80-26a6-4a64-baf1-5ad418236874",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1= pd.melt(performance_df , id_vars = \"Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79152f-7ae3-4389-a566-b53dc903b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6a7b9-752c-4620-8bea-85d7466edf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot( x ='Algorithm', y='value',\n",
    "            hue = 'variable' , data=performance_df1 , kind='bar', height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ecc24d-5b35-4488-afe9-6009a73a7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### modelimprove\n",
    "#### 1. change the max_features parameter of Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc37bf-541c-4490-9d88-8680d393698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm': clfs.keys(), 'Accuracy_max_ft_3000': accuracy_scores, 'Precision_max_ft_3000': precision_scores}).sort_values('Precision_max_ft_3000', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860618dc-a326-4dbc-af07-2b24eac0e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = performance_df.merge(temp_df , on='Algorithm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3771883-003e-4bfd-8c2d-104e8b272cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled = new_df.merge(temp_df , on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe303a9d-8d72-42dd-ac59-e5b44f3f5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm': clfs.keys(), 'Accuracy_num_chars': accuracy_scores, 'Precision_num_chars': precision_scores}).sort_values('Precision_num_chars', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c02642-cc49-4d9d-af94-9c99ad4cd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf602aca-199d-46dd-8fb5-8357a0bee7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting Classifier\n",
    "svc = SVC( kernel= 'sigmoid' , gamma = 1.0, probability=True)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreesClassifier(n_estimators=50,random_state=2)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b52f7-ed3b-45a4-afd3-bff5b0c741c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('svm', svc), ('nb', mnb), ('et',etc)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c9b37-da41-4f3d-a947-6aa83540005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e607bec-92e5-4c4a-a11b-bba6377cacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e964c1-53ff-4566-88c2-481ab324bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying stacking\n",
    "estimators=[('svm', svc), ('nb', mnb), ('et',etc)]\n",
    "final_estimator=RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd59b9b-e02d-452c-b4e2-7104d9b7b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cee87a-6839-421f-a1a3-afa5ba9437ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train , y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d3188-ef48-4c54-9b5b-c6abdfc2485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('vectorizor.pkl','wb'))\n",
    "pickle.dump(mnb,open('model.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5c4a6-327d-4a79-ae8c-db425d275376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# sample text data and corresponding labels( replaces with your actual data)\n",
    "X_train = [\"Sample text 1\", \"Sample text 2\", \"Sample text 3\"]\n",
    "y_train = [0,1,0] #example labels (0 for nagative , 1 for positive)\n",
    "\n",
    "# create and train the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer( lowercase=True , stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# create and train the naive bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf , y_train)\n",
    "\n",
    "#save the trained TF_IDF vectorizer and Naive bayes model to files\n",
    "\n",
    "with open('vectorizer.pkl' , 'wb') as vectorizer_file:\n",
    "    pickle.dump(tfidf , vectorizer_file)\n",
    "\n",
    "with open('model.pkl' , 'wb') as model_file:\n",
    "    pickle.dump(mnb , model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf8984-6eaa-434f-95db-45ec50f4eca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
